### Practical Data Analysis
#### Assignment
by Jeff Leek, PhD, Roger D. Peng, PhD, Brian Caffo, PhD
Coursera June 2014 session 
  
```{r setup, include=FALSE, echo=FALSE}
# set global options
library(knitr)
opts_chunk$set(cache=FALSE,echo=TRUE)
options(width=120)
```

```{r init,echo=FALSE}
rm(list=ls())

library(randomForest)
library(markdown)
library(caret)
set.seed(590607)

dt = Sys.time()
date <- format(dt,"%d-%b-%Y")
time <- format(dt,"%H:%M:%S")
rand <- rnorm(1)

#sessionInfo()
#packageVersion("snow")
Rversion <- version$version.string
```

<style>
body {
    font-size: 1.0em;
    font-family: "Arial, Helvetica, sans-serif"";
}
</style>

#### Introduction

Portable devices can collect large amounts of data about personal activities. 

The goal of this assignment is to build a model predicting the way exercise will be performed by using data from this devices.

This analysis has been performed using R software package for statistical analysis and the following packages.
The version of R used was `r Rversion`.

Document generated on `r date` at `r time`.

#### Loading Data

The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har (section on the Weight Lifting Exercise Dataset).

Datasets:
  - https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv
  - https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv


```{r loadData, echo=FALSE}

# b. load data

# b.1 baseDir will be prefixing all data accesses
baseDir <- ".."

# b.2 create data sub-directory if necessary
dataDir <- file.path(baseDir, "data")
if(!file.exists(dataDir)) { dir.create(dataDir) }

# b.3 download original data if necessary (skip if exists already as it takes time)
# TODO: function
fileName <- "train"
fileExt <- "csv"
fileUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
filePath <- file.path(dataDir, paste(fileName, fileExt, sep="."))
dateFilePath <- file.path(dataDir,paste(fileName,"_date_time_downloaded.txt",sep=""))
if (!file.exists(filePath)) {
  download.file (fileUrl, filePath, method="curl")
  DTDownloaded <- format(Sys.time(), "%Y-%b-%d %H:%M:%S")
  cat (DTDownloaded, file=dateFilePath)
} else {
  DTDownloaded <- scan(file=dateFilePath, what="character", sep="\n")
}
cat ("The training dataset is located at", filePath, "and was downloaded on downloaded on", DTDownloaded)

fileName <- "test"
fileExt <- "csv"
fileUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
filePath <- file.path(dataDir, paste(fileName, fileExt, sep="."))
dateFilePath <- file.path(dataDir,paste(fileName,"_date_time_downloaded.txt",sep=""))
if (!file.exists(filePath)) {
  download.file (fileUrl, filePath, method="curl")
  DTDownloaded <- format(Sys.time(), "%Y-%b-%d %H:%M:%S")
  cat (DTDownloaded, file=dateFilePath)
} else {
  DTDownloaded <- scan(file=dateFilePath, what="character", sep="\n")
}
cat ("The test dataset is located at", filePath, "and was downloaded on downloaded on", DTDownloaded)

# b.4 read dataset and load them in R
trainSetPath <- file.path (dataDir, "train.csv")
testSetPath <-  file.path (dataDir, "test.csv")
trainSet <- read.csv(trainSetPath, header = TRUE) 
testSet  <- read.csv(testSetPath, header = TRUE)
dim(trainSet)
#dim(testSet)
#str(trainSet)
#str(testSet)
#summary(trainSet)
#summary(testSet)

```

#### Pre-processing

The training dataset provided (`r nrow(trainSet)` rows) wil be used to train and test our model, the test dataset provided (`r nrow(testSet)` rows) being used to validate our model.

Let's remove variables not significant and transform to numeric the rest.

```{r preProcessing}
trainSet <- subset(trainSet, select=-c(user_name,X,new_window,num_window, raw_timestamp_part_1, raw_timestamp_part_2,cvtd_timestamp))
testSet <- subset(testSet, select=-c(user_name,X,new_window,num_window, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp))
#trainSet <- trainSet[complete.cases(trainSet),]

nzv <- nearZeroVar(trainSet)
trainSet <- trainSet[-nzv]
testSet <- testSet[-nzv]
ctrain <- nrow(trainSet)
for (i in names(trainSet)) {
  if (i != "classe")  {
    #cat (i, sum(is.na(trainSet[,i]))/ctrain, "\n")
    if (sum(is.na(trainSet[,i]))/ctrain > .9) { # remove col where na > 95%
      trainSet[,i] <- NULL
      testSet[,i] <- NULL
    } else {
      trainSet[,i]  <- as.numeric(trainSet[,i])
      testSet[,i]  <- as.numeric(testSet[,i])
    }
  }
}
#str(trainSet)
```


#### Partitioning

Let's first partition our sample in training and test data:
```{r partitioning}
inTrain <- createDataPartition(y = trainSet$classe, p = 0.7, list = FALSE)
training <- trainSet[inTrain, ]
test <- trainSet[-inTrain, ]
```

#### Training a model

Then, train our model.
```{r training}
model <- randomForest(classe ~ ., training, ntree=200)
model
```


#### In-sample error

Calculating the error through a confusion matrix:
```{r error}
pred <- predict(model, training)
confusionMatrix(pred, training$classe)
```

#### Out of sample error

Let's apply the model to our testing sample and calculate a confusion matrix:
```{r pred}
testing_pred <- predict(model, test)
confusionMatrix(testing_pred, test$classe)
```

#### Validation

We apply the model to predict the 20 test  sample provided and verify the accuracy of the predications:
```{r test}
testSet$pred <- predict(model, testSet)
testSet[,c("problem_id","pred")]
```

### Writing results
```{r write}
n = length(testSet$pred)
for (i in 1:n) {
    filename = paste0("id_", i, ".txt")
    write.table(testSet[i,], file = filename, quote = FALSE, row.names = FALSE, 
        col.names = FALSE)
}
```
#### Conclusion

All tests were predicted correctly on the validation sample (provided).

#### References

1. R Core Team. R: A language and environment for statistical computing. URL: http://www.R-project.org. R Foundation for Statistical Computing, 2013.

2. Seber, George AF, and Alan J. Lee. Linear regression analysis. Vol. 936. Wiley, 2012.

3. R Markdown Page. URL: http://www.rstudio.com/ide/docs/authoring/using_markdown. 

4. Ugulino, W.; Cardador, D.; Vega, K.; Velloso, E.; Milidiu, R.; Fuks, H. Wearable Computing: Accelerometers' Data Classification of Body Postures and Movements. Proceedings of 21st Brazilian Symposium on Artificial Intelligence. Advances in Artificial Intelligence - SBIA 2012. In: Lecture Notes in Computer Science. , pp. 52-61. Curitiba, PR: Springer Berlin / Heidelberg, 2012. ISBN 978-3-642-34458-9. DOI: 10.1007/978-3-642-34459-6_6.

5. http://groupware.les.inf.puc-rio.br/har#sbia_paper_section#ixzz33n5Wpc66
